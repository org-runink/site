version = 1

# ============================================================================
# GLOBAL SETTINGS
# ============================================================================
[*]
# Hardware
threads = 8                     # Maximize parallelism
batch-size = 2048               # Faster prompt processing

# Memory Management
ctx-size = 4096                 # Context window size
mmap = true                     # Memory-mapped file loading
cont-batching = true            # Continuous batching enabled
cache-reuse = 1024              # Token cache reuse threshold

# Monitoring
metrics = true                  # Enable Prometheus metrics

# Inference Parameters
temp = 0.2
top-k = 30
top-p = 0.9
min-p = 0.05
repeat-penalty = 1.1


# ============================================================================
# VECTOR EMBEDDING MODEL (RAG Support)
# ============================================================================

[shepherd-embedding-model]
model = ./models/bge-m3-f16.gguf
embeddings = true
pooling = mean
# Actual vector generation model

# ============================================================================
# BLOG CONTENT GENERATION AGENT (Used by langchaingo + llama-cli)
# ============================================================================

[shepherd-blogger]
model = ./models/gemma-3-4b-it-q4_0/gemma-3-4b-it-q4_0.gguf
chat-template-file = ./models/templates/blogger-chat.jinja
n-predict = 4096                # Extended for full blog articles
temp = 0.7                      # Higher creativity for engaging content
top-k = 40
top-p = 0.92
repeat-penalty = 1.15           # Reduce repetition in long-form content
# Grammar schema must be provided via --grammar-file in llama-cli command
# System prompt embedded in chat template for SEO optimization

# ============================================================================
# AGENT ROUTES (Note: These use the GENERIC shepherd model logic in client)
# ============================================================================
# The client script (test-models-fast.sh) maps these logical names to the
# single [shepherd] model entry above, injecting system prompts dynamically.
# We do NOT need separate entries here for 'shepherd-embedding-agent' or
# 'shepherd-diffusion-agent' because they use the same Gemma 3 model.
# The 'shepherd' entry covers all Chat Agent needs.
# WE ONLY LIST MODELS THAT REQUIRE *DIFFERENT WEIGHTS/BINARIES*.
